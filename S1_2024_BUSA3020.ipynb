{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a6a106c2-f185-492f-87bb-79286c2eacc4",
   "metadata": {},
   "source": [
    "### __BUSA3020 Group Assignment - Predicting Used Car Sale Prices__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c316658-edf7-4797-b078-202987b4922b",
   "metadata": {},
   "source": [
    "--- \n",
    "\n",
    "**Kaggle Competition Ends:** Friday, 31 May 2024 @ 3:00pm (Week 13)  \n",
    "**Assignment Due Date on iLearn:** Friday, 31 May 2024 @ 11.59pm (Week 13)  \n",
    "\n",
    "**Overview:**   \n",
    "\n",
    "- In the group assignment you will form a team of 3 students and participate in a forecasting competition on Kaggle\n",
    "- The goal is to predict prices of used cars based on car characteristics and regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2270744-5e12-447b-a861-9719409e287c",
   "metadata": {},
   "source": [
    "**Instructions:** \n",
    "\n",
    "- Form a team of 3 students \n",
    "- Each team member needs to join [https://www.kaggle.com](https://www.kaggle.com/)  \n",
    "- Choose a team leader and form a team on Kaggle [https://www.kaggle.com/t/ff5fb5beaeb14f7686df98fef9d1c0bc](https://www.kaggle.com/t/ff5fb5beaeb14f7686df98fef9d1c0bc)\n",
    "    - Team leader to click on `team` and join and invite other 2 team members to join\n",
    "    - Your **team's name must start** with our unit code, for instance you could have a team called BUSA3020_algorithm_arena\n",
    "- All team members should work on all the tasks however   \n",
    "    - Each team member will be responsible for one of the 3 tasks listed below    \n",
    "- **Your predictions must be generated by a model you develop here** \n",
    "    - You will receive a mark of **zero** if your code is not able produce the forecasts you submit to Kaggle "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f70e4c-b794-4555-b170-d80b628b2904",
   "metadata": {},
   "source": [
    "**Competition Rankings**\n",
    "\n",
    "The rankings for the competition are determined through two different leaderboards:\n",
    "\n",
    "- **Public Leaderboard Ranking**: Available during the competition, these rankings are calculated based on 50% of the test dataset, which includes 1,500 observations. This allows participants to see how they are performing while the competition is still ongoing.\n",
    "- **Final Leaderboard Ranking**: These rankings are recalculated from the other 50% of the test dataset, which consists of the remaining 1,500 observations, and are revealed 5 minutes after the competition concludes. This final evaluation determines the ultimate standings of the competition.\n",
    "\n",
    "\n",
    "\n",
    "**Marks**: \n",
    "\n",
    "- Total Marks: 40\n",
    "- Your individual mark will consist of:  \n",
    "    - 50% x overall assignment mark + 45% x mark for the task that you are responsible for + 5% x mark received from your teammates for your effort in group work \n",
    "- 1 mark: Ranking in the top 5 positions on the **final** leaderboard for your unit \n",
    "- 3 marks: Reaching the 1st place in your unit according to the **final** leaderboard ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3180e9-c3cc-494c-ae64-d3b9701e10e8",
   "metadata": {},
   "source": [
    "\n",
    "**Submissions:**  \n",
    "\n",
    "1. On Kaggle: submit your team's forecast in order to be ranked by Kaggle\n",
    "    - Limit of 20 submission per day\n",
    "2. On iLearn **only team leader to submit** the assignment Jupyter notebook re-named to your team's name on Kaggle   \n",
    "    - The Jupyter notebook must contain team members names/ID numbers, and the group name Kaggle\n",
    "    - One 15 minute video recording of your work \n",
    "        - 5 marks will be deducted from each Task for which there is no video presentation or if you don't follow the above instructions\n",
    "3. On iLearn each student needs to submit a file with their teammates' names, ID number and a mark for their group effort (out of 100%)\n",
    "    - You don't need to score yourself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbce8a-bf4f-4155-9336-6367fd239f6a",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac487d3-755a-4a69-a22f-d599dbdd7979",
   "metadata": {},
   "source": [
    "**Fill out the following information**\n",
    "\n",
    "- Team Name on Kaggle: `BUSA3020_datanoobs`\n",
    "- Team Leader and Team Member 1: `Chau Anh Cong`\n",
    "- Team Member 2: `Tran Tuan Huy Bui`\n",
    "- Team Member 3: `Thomas Haywood Ruiz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437083a3",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b789f492",
   "metadata": {},
   "source": [
    "**Import Libraries and Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19dd4be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "#pd.set_option(\"display.max_rows\", None, \"display.max_columns\", None, \"display.width\", None) # pretty printing\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, ElasticNetCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, StackingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "import mlflow\n",
    "# mlflow server --backend-store-uri sqlite:///mlflow.db --default-artifact-root ./mlruns\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f270aa5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "df_test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24de689-928d-4991-b337-760c12780e5d",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Task 1: Problem Description and Initial Data Analysis\n",
    "\n",
    "1. Based on the Competition Overview, datasets and additional information provided on Kaggle, along with insights gained from personal research of the topic, write **Problem Description** (about 500 words) focusing on the sections listed below: \n",
    "- Forecasting Problem - explain what we are trying to do and how it could be used in the real world, e.g. who and how may benefit from it (3 marks)    \n",
    "- Evaluation Criteria - discuss the criteria that  is used to assess forecasting performance in detail (3 marks)     \n",
    "- Categorise the variables provided in the dataset according to their type; Hint: similar to what we had in Programming Task 1 (2 marks)  \n",
    "- Missing Values - only explain what you find for both the training and test datasets at this stage (2 marks)\n",
    "- Provide and discuss some interesting *univariate* summary statistics and distributions in the training dataset  (2 marks)       \n",
    "- Other Hints:\n",
    "    - You should **not** discuss any specific predictive algorithms at this stage\n",
    "    - Minimise the number of cells you use to enhance presentation and readability\n",
    "\n",
    "**Total Marks: 12**   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bf17ce-2bc0-45b9-9398-0935afe218db",
   "metadata": {},
   "source": [
    "Student in charge of this task: `Thomas Haywood Ruiz`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24870b7-38a1-4467-8370-2675612f0ec2",
   "metadata": {},
   "source": [
    "The primary goal of this project is to develop a model that can accurately predict the prices of listed cars based on certain vehicle features, such as year, horsepower, fuel economy, and power etc. The information collected from this analysis will inform stakeholders of the impact of specific features on car price value. Consumers can leverage the findings to make a more informed decision when buying or selling a vehicle. Car dealerships and online marketplaces can optimise  their pricing strategies based on features that have the most impact on car value. Additionally, insurance companies can utilise this data to determine insurance premiums based on car value.\n",
    "\n",
    "The evaluation criteria for assessing the performance of the forecast model will be measured on the mean absolute percentage error (MAPE). This error metric will indicate the regression modelâ€™s performance by comparing the average percentage difference between the predicted and actual prices. For selecting a suitable model, the MAPE results of different forecast models will be contrasted, and the model with the lowest MAPE score will be utilised for the car value analysis. Although MAPE is a widely utilised metric for forecast evaluation, it is sensitive to outliers which may skew the forecasting evaluation accuracy. Therefore, to ensure the reliability and integrity of the results, this limitation will be carefully considered in the analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9860cce-1961-4444-85f9-f2b1511fa0cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ADD Count for types, and add Date Type, and Text (torque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049c0e8-1c7b-4dbe-a7ff-57a2381b7f37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['transmission_display'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfffee94-794a-4fb1-85e7-3c56ced0ffd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(df['torque'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa2744-f823-4130-badc-5bb1dcb8f9fd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb82206-d99a-47f0-bca6-c4259c1c6b7f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c2e04c-a32f-4a6b-853a-016a4d6c0c76",
   "metadata": {},
   "source": [
    "Based on the missing values of both data sets, the test set contains more variables with missing values than the training set. To ensure the reliability of the analysis, these missing values need to be handled appropriately during data preprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04a157c-c5da-4f8a-a633-1a0e4cbc939a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fb232c-61ca-4456-973f-f645db10a451",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(df['price'])\n",
    "plt.title('Distribution of price')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n",
    "print(df['price'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f3920b-058e-49c8-99f8-e7349370dc82",
   "metadata": {},
   "source": [
    "These statistics on price distribution reflect market trends, product demand, and availibilities of certain vehicles. The average price of listed cars is approximately `$28851` which gives insight into typical range of car prices, so more regular priced vehicles are being advertised due to the higher availability of lower end cars. The 75th percentile is `$36992` which indicates that 75% of listed cars falls below this value, so typically regular priced cars are being listed over higher end; however, the presence of higher outliers reveals that there still are some high-end luxury cars being listed too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ce293ac-8b50-42a1-a8f8-2c586775c24c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "make_counts = df['make_name'].value_counts()\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "make_counts.plot(kind='bar')\n",
    "plt.title('Counts of Car Makes')\n",
    "plt.xlabel('Car Make')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864fa505-4f17-4b65-9cb9-9b4a81e99723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0908cd3-05d2-49e4-a3c5-57bd8b8ac80e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['year'].value_counts().sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "600c9cac-8d88-4725-b938-bc55d652aad8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print(df['year'] == 2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f63eb4-0247-417b-b2bc-7e7251a9e3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "year_counts = df['year'].value_counts().sort_index() \n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "year_counts.plot(kind='bar')\n",
    "plt.title('Count of Cars per year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6455a55-cd55-4697-9435-560a2028f131",
   "metadata": {},
   "source": [
    "Based on the graph above, there is a higher frequency of more recently manufactured cars being listed compared to older ones. Additionally, considering the price distribution graph, most of these later-made vehicles are priced cheaper which indicates that the year of manufacture may affect the price of a car's value. Moreover, the substantial increase in number of cars listed in 2020 compared to other years suggests several possible reasons:\n",
    "\n",
    "* There is a high demand for cars manufactured in 2020\n",
    "* More people are trying to sell their car made in 2020\n",
    "* There was a major increase in car manufacturing in 2020 with more vehicles being created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44fce129-a014-43f5-be88-0b67033b7b25",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(df['is_new'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc7e303-4547-4c74-94c8-e436386b5127",
   "metadata": {},
   "source": [
    "The split between new and old cars is fairly close"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fff026c",
   "metadata": {},
   "source": [
    "Table listing all the features present in the dataset and their type\n",
    "\n",
    "|Variable Kind|Number of Features|Feature Names|\n",
    "| --- | --- | --- |\n",
    "| Numeric | 18 |  `city_fuel_economy`, `daysonmarket`, `engine_displacement`, `highway_fuel_economy`, `horsepower`, `latitude`, `longitude`, `mileage`, `savings_amount`, `seller_rating`    |\n",
    "| Nominal  | 16 | `vin`, `body_type`, `city`, `dealer_zip`, `engine_type`, `exterior_color`, `franchise_dealer` `fuel_type`, `interior_color`, `is_new`, `listing_color`, `make_name`, `model_name`, `transmission`, `transmission_display`, `wheel_system` |\n",
    "| Date  | 16 | `listed_date`, `year` |\n",
    "| Text  | 16 | `back_legroom`, `front_legroom`, `fuel_tank_volume`, `height`, `length`, `maximum_seating`, `wheelbase`, `width`, `power`, `torque` |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad30df24-b18b-4f61-975f-ceebe2e2c3ab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Task 2: Data Cleaning, Missing Observations and Feature Engineering\n",
    "- In this task you need to follow a set of instructions/questions listed below.\n",
    "- Make sure you explain each answer carefully both in Markdown text, as well as on your video.\n",
    "\n",
    "**Total Marks: 12**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f2d91-d79b-403b-9046-950e9b769cfb",
   "metadata": {},
   "source": [
    "Student in charge of this task: `Tran Tuan Huy Bui`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93823fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Cleaner:\n",
    "\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "\n",
    "\n",
    "    def extract_numerical_values(self, features: list):\n",
    "        for feature in features:\n",
    "            self.df[feature] = self.df[feature].str.split().str[0]\n",
    "            self.df[feature] = pd.to_numeric(self.df[feature], errors='coerce')\n",
    "        #return self.df\n",
    "\n",
    "\n",
    "    def extract_multiple_numerical_values(self, feature:str, value1:str, value2:str):\n",
    "        '''\n",
    "        Extracts two numerical values from a torque and power\n",
    "        '''\n",
    "\n",
    "        self.df[value1] = self.df[feature].str.extract(r'(\\d+)', expand=False)\\\n",
    "                                        .apply(pd.to_numeric, errors='coerce')\n",
    "                                        \n",
    "        self.df[value2] = self.df[feature].str.extract(r'@\\s*(\\d+,?\\d*)', expand=False)\n",
    "        self.df[value2] = self.df[value2].str.replace(r',', '', regex=True)\\\n",
    "                                        .apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "        del self.df[feature]\n",
    "\n",
    "\n",
    "    def impute_numerical_columns(self, numerical_cols:list):\n",
    "        self.df[numerical_cols] = self.df.loc[:, numerical_cols] \\\n",
    "                                    .fillna(self.df[numerical_cols].mean(axis=0))        \n",
    "\n",
    "\n",
    "    def impute_categorical_columns(self, categorical_cols:list):\n",
    "        self.df[categorical_cols] = self.df.loc[:, categorical_cols] \\\n",
    "                                    .fillna(self.df[categorical_cols].mode(axis=0).iloc[0])\n",
    "    \n",
    "    \n",
    "\n",
    "train_cleaner = Cleaner(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f4ec3d-4936-4428-a204-04f133210a3d",
   "metadata": {},
   "source": [
    "**Task 2, Question 1**: Clean **all** numerical features so that they can be used in training algorithms. For instance, back_legroom feature is in object format containing both numerical values and text. Extract numerical values (equivalently eliminate the text) so that the numerical values can be used as a regular feature.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb97a6b-daee-4898-983e-097eb3c21dd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_one_item_col = ['back_legroom','front_legroom', \n",
    "                  'fuel_tank_volume', 'height', 'length', \n",
    "                  'maximum_seating', 'wheelbase', 'width']\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fdcad8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cleaner.extract_numerical_values(num_one_item_col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313fef0-4043-4c03-8f3f-4691b5f61f11",
   "metadata": {},
   "source": [
    "`(Task 2, Question 1 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "773f1bb1",
   "metadata": {},
   "source": [
    "**Task 2, Question 2** Create at least 5 new features from the existing numerical variables which contain multiple items of information, for example you could extract maximum torque and torque rpm from the torque variable.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617e6e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cleaner.extract_multiple_numerical_values('torque', 'max_torque', 'torque_rpm')\n",
    "train_cleaner.extract_multiple_numerical_values('power', 'max_power', 'power_rpm')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eff92ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_cleaner.df['car_age'] = 2024 - train_cleaner.df['year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fde9b6-bed0-4018-9edb-3553f3d1fa13",
   "metadata": {},
   "source": [
    "`(Task 2, Question 2 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d01c4d-1412-4e51-8f80-7040f536b1c7",
   "metadata": {},
   "source": [
    "**Task 2, Question 3**: Impute the missing values for all features in both the training and test datasets.   \n",
    "(3 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36412d68-f68f-4764-aa6f-88ba33116ef3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 2, Question 3 Code Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b734c74a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "numerical_cols = ['back_legroom', 'city_fuel_economy', 'daysonmarket', 'engine_displacement', \n",
    "                  'front_legroom', 'fuel_tank_volume', 'height', 'highway_fuel_economy', 'horsepower', \n",
    "                  'latitude', 'longitude', 'length', 'maximum_seating', 'mileage', 'savings_amount', \n",
    "                  'seller_rating', 'max_torque', 'torque_rpm', 'max_power', 'power_rpm', 'wheelbase', 'width']\n",
    "\n",
    "train_cleaner.impute_numerical_columns(numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f965c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_cols = ['body_type', 'city', 'dealer_zip', 'engine_type', 'exterior_color', 'franchise_dealer', 'fuel_type',\n",
    "                    'interior_color', 'is_new', 'listing_color', 'make_name', 'model_name', 'transmission', 'transmission_display', 'wheel_system']\n",
    "\n",
    "train_cleaner.impute_categorical_columns(categorical_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb16b1d-f4f1-438e-a5af-ae9cc3c04467",
   "metadata": {},
   "source": [
    "`(Task 2, Question 3 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c14ab6-aff9-4fcd-ab7b-34f0b77f8caa",
   "metadata": {},
   "source": [
    "**Task 2, Question 4**: Encode all categorical variables appropriately as discussed in class. \n",
    "\n",
    "- Where multiple values are given for an observation encode the observation as 'other'. \n",
    "- Where a categorical feature contains more than 5 unique values, map the features into 5 most frequent values + 'other' and then encode appropriately. For instance, map colours into 5 basic colours + 'other': [red, yellow, green, blue, purple, other] and then encode.  \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42a624b-996c-41e0-984e-0d622e9da420",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Task 2, Question 4 Code Here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230a9366-6eae-4de9-ab2e-16a41aeeb27e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def encode_multiple_values(df, column):\n",
    "    \"\"\"\n",
    "    Encodes observations with multiple values for a column as 'other'\n",
    "    \"\"\"\n",
    "    # Create a boolean mask for rows with multiple values\n",
    "    multi_value_mask = df[column].apply(lambda x: isinstance(x, list) or isinstance(x, set))\n",
    "    \n",
    "    # Replace multiple values with 'other'\n",
    "    df.loc[multi_value_mask, column] = 'other'\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeb50e2-6e50-478c-b09a-0083f404d9f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_cleaner.df.head()\n",
    "# train_cleaner.df.info()\n",
    "\n",
    "# Create a copy\n",
    "df_encode = train_cleaner.df.copy()\n",
    "# df_encode.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc349161-1f56-4b3f-a384-6da45b0467dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def most_frequent(df, feature, n):\n",
    "    # Create a dataframe to check the most frequent values of each categorical feature\n",
    "    # Create a list of values for the single column\n",
    "    values = [1, 2, 3, 4, 5]\n",
    "\n",
    "    # Create the DataFrame with a single column\n",
    "    most_fq_df = pd.DataFrame({'Column1': values})\n",
    "\n",
    "    for feat in feature:\n",
    "        value_counts = df[feat].value_counts().head(n)\n",
    "\n",
    "        top_values_df = value_counts.reset_index()\n",
    "\n",
    "        del top_values_df['count']\n",
    "\n",
    "        most_fq_df = pd.concat([most_fq_df, top_values_df], axis=1)\n",
    "\n",
    "    del most_fq_df['Column1']\n",
    "\n",
    "    return most_fq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47039ed1-f7b7-4f03-a4a8-07b6649629b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the list of colors\n",
    "color = ['black', 'white', 'gray', 'silver', 'red', 'yellow', 'green', 'blue', 'purple', 'other']\n",
    "\n",
    "# Convert the list of colors to a set for faster lookup\n",
    "color_set = set(color)\n",
    "\n",
    "# Create a function to check if any word in the observation matches a color\n",
    "def match_color(observation):\n",
    "    # Convert the observation to lowercase for case-insensitive matching\n",
    "    observation = str(observation).lower()\n",
    "    \n",
    "    # Check if any word in the observation matches a color\n",
    "    for word in observation.split():\n",
    "        if word in color_set:\n",
    "            return word\n",
    "    \n",
    "    # If no match is found, return 'other'\n",
    "    return 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3da10-9bf9-420d-b387-124bc45726ea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "allCatMostFrequent_df = most_frequent(df_encode, categorical_cols, 5)\n",
    "allCatMostFrequent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdbfe6b-5276-4bfd-bd8e-9ad7f0f25d7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "colorFeat = ['exterior_color', 'interior_color', 'listing_color']\n",
    "df_color = df_encode[colorFeat].copy()\n",
    "\n",
    "# Apply the match_color function to the 'df_color'\n",
    "for feat in colorFeat:\n",
    "    df_color[f'matched_color_{feat}'] = df_encode[feat].apply(match_color)\n",
    "    \n",
    "# df_color.head()\n",
    "\n",
    "matchedColorFeat = ['matched_color_exterior_color', 'matched_color_interior_color', 'matched_color_listing_color']\n",
    "allColorFeatMostFrequent_df = most_frequent(df_color, matchedColorFeat, 100)\n",
    "\n",
    "allColorFeatMostFrequent_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91f4448-8574-4397-a636-d83bbde885e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for feat in categorical_cols:\n",
    "#     encode_multiple_values(df_encode, feat)\n",
    "    \n",
    "#     # Convert the column to string before using str accessor\n",
    "#     df_encode[feat] = df_encode[feat].astype(str)\n",
    "    \n",
    "    \n",
    "#     other_count = df[feat].str.contains('other').sum()\n",
    "#     print(f\"Number of observations {feat} encoded as 'other': {other_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3ad3f20-7549-4b9e-8894-818c976d1457",
   "metadata": {},
   "source": [
    "`(Task 2, Question 4 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d695347",
   "metadata": {},
   "source": [
    "**Task 2, Question 5**: Perform any other actions you think need to be done on the data before constructing predictive models, and clearly explain what you have done.   \n",
    "(1 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a238a3-5432-4058-8b6e-1172c4e396ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 5 Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823a081c-cdc4-4fc8-9bd7-52bfd4c3e6dd",
   "metadata": {},
   "source": [
    "`(Task 2, Question 5 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa16475c",
   "metadata": {},
   "source": [
    "**Task 2, Question 6**: Perform some EDA to measure the relationship between the features and the target and carefully explain your findings. \n",
    "(2 marks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1509b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Task 2, Question 6 Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a965eb-e661-4772-af72-98f19e1bae41",
   "metadata": {},
   "source": [
    "`(Task 2, Question 6 Text Here - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9f6968-d9c2-422f-9935-eba856b3c028",
   "metadata": {},
   "source": [
    "--- \n",
    "## Task 3: Fit and tune a forecasting model, submit predictions & win competition\n",
    "\n",
    "Make sure you **clearly explain each step** you do both in Markdown and on the recoded video.   \n",
    "*In this task you must not create any additional features and should only relly on the datasets constructed in Task 2.*\n",
    "\n",
    "1. Build and explain at least 3 machine learning (ML) regression models taking into account the outcomes of Tasks 1 & 2 (3 marks)    \n",
    "2. Fit the models and tune hyperparameters via cross-validation: make sure you comment and explain each step clearly (3 marks)   \n",
    "3. Select your best algorithm, create predictions using the test dataset, and submit your predictions on Kaggle's competition page. Make sure you explain all the steps that led you to chose this algorithm both in the video presentation and in your written answer. (4 marks)   \n",
    "4. Provide Kaggle ranking and score (screenshot your final submission) and comment (e.g. how could you improve your ranking?) (2 mark)   \n",
    "\n",
    "- Hints:\n",
    "    - To perform well you will need to iterate Tasks 2 and Task 3\n",
    "    - Make sure your Python code works, so that a marker that can replicate your Kaggle submission and score.\n",
    "    - You will receive the mark of zero if your code does not produce the forecasts uploaded to Kaggle \n",
    "\n",
    "**Total Marks: 12**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73204de-1ad7-46bd-b47c-dd77a09b075d",
   "metadata": {},
   "source": [
    "Student in charge of this task: `Chau Anh Cong`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59883412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train_cleaner.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7367cbd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_train['price']\n",
    "X = df_train[numerical_cols]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75384c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_experiment(\"Group Assignment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbf6ed1",
   "metadata": {},
   "source": [
    "## Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114f2809",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Linear Regression\"):\n",
    "\n",
    "    # Train a model\n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"linear_model\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mape\", mape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ee52e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Ridge Regression\"):\n",
    "\n",
    "    # Train a model\n",
    "    model = RidgeCV(alphas=[0.001, 0.01, 0.1, 1, 10, 100, 1000])\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"ridge_model\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    \n",
    "    alpha = model.alpha_\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"alpha\", alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b153f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Lasso Regression\"):\n",
    "\n",
    "    # Train a model\n",
    "    model = RidgeCV(alphas=np.logspace(-4, 1, 50))\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"lasso_model\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    \n",
    "    alpha = model.alpha_\n",
    "    # Log parameters\n",
    "    mlflow.log_param(\"alpha\", alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d60839e0",
   "metadata": {},
   "source": [
    "## Non-linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220b9ac2",
   "metadata": {},
   "source": [
    "### SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1def7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"SVR Regression\"):\n",
    "\n",
    "    param_grid = {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1],\n",
    "    }\n",
    "\n",
    "    # Initialize the SVR\n",
    "    svr = SVR()\n",
    "\n",
    "    # Initialize the RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(estimator=svr, param_distributions=param_grid, \n",
    "                                        cv=5, refit=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    model = random_search.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"svr_model\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    \n",
    "    params = random_search.best_params_\n",
    "\n",
    "    # Log parameters\n",
    "    mlflow.log_param('C', params['C'])\n",
    "    mlflow.log_param('kernel', params['kernel'])\n",
    "    mlflow.log_param('gamma', params['gamma'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792b004f",
   "metadata": {},
   "source": [
    "### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"Random Forest Regression\"):\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 500, 1000],\n",
    "        'max_depth': [10, 20, 30, 40, 50],\n",
    "    }\n",
    "\n",
    "    # Initialize the Random Forest Regressor\n",
    "    rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "    # Initialize the RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, \n",
    "                                        cv=5, refit=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    model = random_search.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    \n",
    "    params = random_search.best_params_\n",
    "    # Log parameters\n",
    "    mlflow.log_param('n_estimators', params['n_estimators'])\n",
    "    mlflow.log_param('max_depth', params['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130bad8",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea8a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"AdaBoost Regression\"):\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [500, 600, 700],\n",
    "        'learning_rate': [0.5, 0.6, 0.7, 0.8],\n",
    "        'estimator': [\n",
    "            DecisionTreeRegressor(max_depth=1),\n",
    "            DecisionTreeRegressor(max_depth=5)\n",
    "        ],\n",
    "        'loss': ['linear', 'square', 'exponential']\n",
    "    }\n",
    "\n",
    "    # Initialize the AdaBoost Regressor\n",
    "    adb = AdaBoostRegressor(random_state=42)\n",
    "\n",
    "    # Initialize the RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(estimator=adb, param_distributions=param_grid, \n",
    "                                        cv=5, refit=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    model = random_search.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"adaboost_model\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    \n",
    "    params = random_search.best_params_\n",
    "    # Log parameters\n",
    "    mlflow.log_param('n_estimators', params['n_estimators'])\n",
    "    mlflow.log_param('learning_rate', params['learning_rate'])\n",
    "    mlflow.log_param('base_estimator', params['estimator'])\n",
    "    mlflow.log_param('loss', params['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20aaf73d",
   "metadata": {},
   "source": [
    "### XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaefa830",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(run_name=\"XGBoost Regression\"):\n",
    "\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 500, 1000],\n",
    "        'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "        'max_depth': [3, 5, 7, 10]\n",
    "    }\n",
    "\n",
    "    # Initialize the XGBoost Regressor\n",
    "    xg_reg = XGBRegressor(random_state=42)\n",
    "\n",
    "    # Initialize the RandomizedSearchCV\n",
    "    random_search = RandomizedSearchCV(estimator=xg_reg, param_distributions=param_grid, \n",
    "                                        cv=5, refit=True, random_state=42, n_jobs=-1)\n",
    "\n",
    "    # Fit the model\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Get the best parameters\n",
    "    model = random_search.best_estimator_\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = model.predict(X_test)\n",
    "    \n",
    "    # Log model\n",
    "    mlflow.sklearn.log_model(model, \"xgboost_model\")\n",
    "    \n",
    "    # Log metrics\n",
    "    mape = mean_absolute_percentage_error(y_test, predictions)\n",
    "    mlflow.log_metric(\"mape\", mape)\n",
    "    \n",
    "    params = random_search.best_params_\n",
    "    # Log parameters\n",
    "    mlflow.log_param('n_estimators', params['n_estimators'])\n",
    "    mlflow.log_param('learning_rate', params['learning_rate'])\n",
    "    mlflow.log_param('max_depth', params['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "727a76ed",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d24ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "logged_model = 'runs:/c7b064ab714b49139e5eccee7d96b7be/xgboost_model'\n",
    "\n",
    "# Load model as a PyFuncModel.\n",
    "model = mlflow.pyfunc.load_model(logged_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8114793",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cleaner = Cleaner(df_test)\n",
    "\n",
    "test_cleaner.extract_numerical_values(num_one_item_col)\n",
    "test_cleaner.extract_multiple_numerical_values('torque', 'max_torque', 'torque_rpm')\n",
    "test_cleaner.extract_multiple_numerical_values('power', 'max_power', 'power_rpm')\n",
    "test_cleaner.df['car_age'] = 2024 - test_cleaner.df['year']\n",
    "test_cleaner.impute_numerical_columns(numerical_cols)\n",
    "test_cleaner.impute_categorical_columns(categorical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf329441",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submit = test_cleaner.df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16b83d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"vin\": df_test['vin'].values, \"price\": model.predict(df_submit[numerical_cols])})\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1010e5-03e6-475b-a9f8-51b19cb556d2",
   "metadata": {},
   "source": [
    "`(Task 3 - insert more cells as required)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23beb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f9e532-0b89-45db-812e-4a4cf0847ab0",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "## Marking Criteria\n",
    "\n",
    "To receive full marks your solutions must satisfy the following criteria:\n",
    "\n",
    "- Problem Description: 12 marks\n",
    "- Data Cleaning: 12 marks\n",
    "- Building Forecasting models: 12 marks\n",
    "- Competition Points: 4 marks\n",
    "- Forecasts correctly uploaded to Kaggle\n",
    "- Python code is clean and concise\n",
    "- Written explanations are provided in clear and easy to understand sentences\n",
    "- Video presentations are limited to 15 minutes in duration\n",
    "- Each team member delivers a 5-minute presentation on their assigned task\n",
    "    - During the video recording, make sure that both your face and Jupyter Notebook are clearly visible\n",
    "    - Your code must be readable on the video\n",
    "    - Discuss both the actions you took and, more importantly, the reasoning behind these actions, explaining the significance of key steps\n",
    "- The assignment notebook is well-organised and easy to follow\n",
    "- Failure to meet the above marking criteria will result in a deduction of marks\n",
    "\n",
    "---\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
